import 'dart:async';
import 'dart:developer' as dev;

import 'package:drift/drift.dart';
import 'package:flutter/material.dart';

import 'package:gtdoro/data/local/app_database.dart';
import 'package:gtdoro/data/local/oracle_serialization.dart';
import 'package:gtdoro/data/sync/oracle/data/document_helper.dart';
import 'package:gtdoro/data/repositories/action_repository.dart';
import 'package:gtdoro/data/repositories/context_repository.dart';
import 'package:gtdoro/data/repositories/recurring_action_repository.dart';
import 'package:gtdoro/data/repositories/scheduled_action_repository.dart';
import 'package:gtdoro/core/config/app_config.dart';
import 'package:gtdoro/core/constants/app_strings.dart';
import 'package:gtdoro/core/constants/sync_constants.dart';
import 'package:gtdoro/data/sync/oracle/cache/manager.dart';
import 'package:gtdoro/data/sync/oracle/error/handler.dart';
import 'package:gtdoro/data/sync/oracle/network/network_monitor.dart'
    show OracleNetworkMonitor, NetworkStatusListener;
import 'package:gtdoro/data/sync/models/connection_test_result.dart';
import 'package:gtdoro/data/sync/models/sync_config.dart' as model;
import 'package:gtdoro/data/sync/models/sync_progress.dart';
import 'package:gtdoro/data/sync/models/sync_statistics.dart';
import 'package:gtdoro/data/sync/oracle/core/sync_service.dart';
import 'package:gtdoro/data/sync/oracle/core/metadata_extractor.dart';
import 'package:gtdoro/data/sync/oracle/utils/rev_helper.dart';
import 'package:gtdoro/data/sync/providers/sync_data_merger.dart';
import 'package:gtdoro/features/todo/providers/action_provider.dart';
import 'package:gtdoro/features/todo/providers/context_provider.dart';
import 'package:gtdoro/features/todo/providers/recurring_provider.dart';

class SyncProvider with ChangeNotifier {
  final AppDatabase _db;
  final OracleSyncService _oracleSyncService = OracleSyncService();
  final ActionRepository _actionRepo;
  final ContextRepository _contextRepo;
  final RecurringActionRepository _recurringRepo;
  final ScheduledActionRepository _scheduledRepo;
  late SyncDataMerger _dataMerger;

  // Kept for potential future use (e.g., manual refresh, direct provider access)
  // ignore: unused_field
  final ActionProvider _actionProvider;
  // ignore: unused_field
  final ContextProvider _contextProvider;
  // ignore: unused_field
  final RecurringProvider _recurringProvider;

  model.SyncConfig _config = model.SyncConfig();
  bool _isSyncing = false;
  DateTime? _lastSyncDisplayTime;
  DateTime? _lastSyncTimestamp;
  String? _errorMessage;
  SyncProgress? _currentProgress;
  SyncStatistics _statistics = SyncStatistics(
    totalSyncs: 0,
    successfulSyncs: 0,
    failedSyncs: 0,
  );

  model.SyncConfig get config => _config;
  bool get isSyncing => _isSyncing;
  DateTime? get lastSyncDisplayTime => _lastSyncDisplayTime;
  String? get errorMessage => _errorMessage;
  SyncProgress? get currentProgress => _currentProgress;
  SyncStatistics get statistics => _statistics;
  
  bool get canSync => AppConfig.oracleDbApiUrl.isNotEmpty;
      // ë™ê¸°í™”ëŠ” í•­ìƒ í™œì„±í™”ë¨ (ìë™ ë™ê¸°í™”)
      // URLì€ AppConfigì—ì„œ ê´€ë¦¬
  
  /// ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ
  bool get isNetworkOnline => OracleNetworkMonitor().isOnline;
  
  /// Oracle DB ì—°ê²° ìƒíƒœ (null: í™•ì¸ ì•ˆí•¨, true: ì—°ê²°ë¨, false: ì—°ê²° ì•ˆë¨)
  bool? get isOracleConnected => _isOracleConnected;
  
  /// ì—°ê²° ìƒíƒœ í™•ì¸ ì—¬ë¶€
  bool get isConnectionChecked => _isConnectionChecked;
  
  /// ë§ˆì§€ë§‰ ì—°ê²° í™•ì¸ ì‹œê°„
  DateTime? get lastConnectionCheckTime => _lastConnectionCheckTime;
  
  /// ì—°ê²° ìƒíƒœ í…ìŠ¤íŠ¸
  String get connectionStatusText {
    if (!isConnectionChecked) {
      return 'ì—°ê²° ìƒíƒœ í™•ì¸ ì¤‘...';
    }
    if (!isNetworkOnline) {
      return 'ë„¤íŠ¸ì›Œí¬ ì˜¤í”„ë¼ì¸';
    }
    if (_isOracleConnected == null) {
      return 'ì—°ê²° ìƒíƒœ í™•ì¸ ë¶ˆê°€';
    }
    if (_isOracleConnected ?? false) {
      return 'ì—°ê²°ë¨';
    }
    return 'ì—°ê²° ì•ˆë¨';
  }

  SyncProvider({
    required AppDatabase db,
    required ActionRepository actionRepo,
    required ContextRepository contextRepo,
    required RecurringActionRepository recurringRepo,
    required ScheduledActionRepository scheduledRepo,
    required ActionProvider actionProvider,
    required ContextProvider contextProvider,
    required RecurringProvider recurringProvider,
  })  : _db = db,
        _actionRepo = actionRepo,
        _contextRepo = contextRepo,
        _recurringRepo = recurringRepo,
        _scheduledRepo = scheduledRepo,
        _actionProvider = actionProvider,
        _contextProvider = contextProvider,
        _recurringProvider = recurringProvider {
    _dataMerger = SyncDataMerger(_actionRepo, _contextRepo, _recurringRepo, _scheduledRepo);
  }

  Timer? _autoSyncTimer;
  Timer? _debounceSyncTimer; // ì‹¤ì‹œê°„ ë™ê¸°í™” debounce íƒ€ì´ë¨¸
  DateTime? _lastSyncAttemptTime; // ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹œë„ ì‹œê°„ (ë„ˆë¬´ ë¹ ë¥¸ ì—°ì† ë™ê¸°í™” ë°©ì§€)
  NetworkStatusListener? _networkStatusListener; // ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ë¦¬ìŠ¤ë„ˆ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
  bool _isConnectionChecked = false; // ì—°ê²° ìƒíƒœ í™•ì¸ ì—¬ë¶€
  bool? _isOracleConnected; // Oracle DB ì—°ê²° ìƒíƒœ (null: í™•ì¸ ì•ˆí•¨, true: ì—°ê²°ë¨, false: ì—°ê²° ì•ˆë¨)
  DateTime? _lastConnectionCheckTime; // ë§ˆì§€ë§‰ ì—°ê²° í™•ì¸ ì‹œê°„

  Future<void> init() async {
    try {
      await _loadConfig();
      notifyListeners();

      // ì´ë²¤íŠ¸ ê¸°ë°˜ ë™ê¸°í™” ì„¤ì • (í™”ë©´ ì „í™˜ ë° ë°ì´í„° ë³€ê²½ ì‹œ)
      if (canSync) {
        debugPrint('SyncProvider: Event-based sync enabled (triggers: app start, screen change, data modification)');
        dev.log('SyncProvider: Event-based sync enabled');
        
        _checkConnectionStatus();
        _startPeriodicConnectionCheck();
        
        // ì•± ì‹œì‘ ì‹œ ì´ˆê¸° ë™ê¸°í™” (2ì´ˆ í›„)
        Future.delayed(const Duration(seconds: 2), () {
          if (canSync && !_isSyncing) {
            startSync(retryOnFailure: true);
          }
        });
      }
    } catch (e, stackTrace) {
      dev.log('SyncProvider Init Error', error: e, stackTrace: stackTrace);
    }
  }

  /// í™”ë©´ ì „í™˜ ì‹œ ë™ê¸°í™” íŠ¸ë¦¬ê±° (NavigationProviderì—ì„œ í˜¸ì¶œ)
  void triggerSyncOnScreenChange() {
    if (!canSync || _isSyncing) return;
    
    // ìµœì†Œ ê°„ê²© ì²´í¬
    if (_lastSyncAttemptTime != null) {
      final timeSinceLastSync = DateTime.now().difference(_lastSyncAttemptTime!);
      if (timeSinceLastSync < SyncConstants.minSyncInterval) {
        return; // ë„ˆë¬´ ë¹ ë¥¸ ì—°ì† ë™ê¸°í™” ë°©ì§€
      }
    }
    
    triggerImmediateSync();
  }
  
  Timer? _connectionCheckTimer;
  
  /// ì£¼ê¸°ì  ì—°ê²° ìƒíƒœ í™•ì¸ ì‹œì‘
  void _startPeriodicConnectionCheck() {
    _connectionCheckTimer?.cancel();
    _connectionCheckTimer = Timer.periodic(const Duration(seconds: 30), (timer) {
      if (canSync) {
        _checkConnectionStatus();
      }
    });
  }
  
  /// ì£¼ê¸°ì  ì—°ê²° ìƒíƒœ í™•ì¸ ì¤‘ì§€
  void _stopPeriodicConnectionCheck() {
    _connectionCheckTimer?.cancel();
    _connectionCheckTimer = null;
  }
  
  /// ì—°ê²° ìƒíƒœ í™•ì¸ (ë¹„ë™ê¸°, UI ë¸”ë¡œí‚¹ ì—†ìŒ)
  Future<void> _checkConnectionStatus() async {
    if (!canSync) return;
    
    try {
      // ë„¤íŠ¸ì›Œí¬ ìƒíƒœ í™•ì¸
      final networkMonitor = OracleNetworkMonitor();
      if (networkMonitor.isStatusStale) {
        await networkMonitor.checkNetworkStatus();
      }
      
          // Oracle DB ì—°ê²° í™•ì¸ (ë„¤íŠ¸ì›Œí¬ê°€ ì˜¨ë¼ì¸ì¼ ë•Œë§Œ)
          bool? oracleConnected;
          if (networkMonitor.isOnline) {
            try {
              final tempConfig = _createTempConfig();
              final isConnected = await _oracleSyncService.checkConnection(tempConfig);
              oracleConnected = isConnected;
              _lastConnectionCheckTime = DateTime.now();
            } catch (e) {
              dev.log('SyncProvider: Connection check failed', error: e);
              oracleConnected = false;
            }
          } else {
            oracleConnected = false;
          }
      
      _isOracleConnected = oracleConnected;
      _isConnectionChecked = true;
      _lastConnectionCheckTime = DateTime.now();
      notifyListeners();
    } catch (e, stackTrace) {
      dev.log('SyncProvider: Error checking connection status', error: e, stackTrace: stackTrace);
      _isConnectionChecked = true;
      _isOracleConnected = false;
      _lastConnectionCheckTime = DateTime.now();
      notifyListeners();
    }
  }
  
  /// ìˆ˜ë™ ì—°ê²° ìƒíƒœ í™•ì¸ (UIì—ì„œ í˜¸ì¶œ ê°€ëŠ¥)
  Future<void> checkConnectionStatus() async {
    _isConnectionChecked = false;
    _isOracleConnected = null;
    notifyListeners();
    await _checkConnectionStatus();
  }

  /// ì´ë²¤íŠ¸ ê¸°ë°˜ ë™ê¸°í™” íŠ¸ë¦¬ê±° (debounce ì ìš©)
  /// ë°ì´í„° ë³€ê²½ ì‹œ í˜¸ì¶œë˜ë©°, ìµœì†Œ ê°„ê²©ê³¼ debounceë¥¼ í†µí•´ ê³¼ë„í•œ ë™ê¸°í™” ë°©ì§€
  void triggerImmediateSync() {
    if (!canSync || _isSyncing) {
      return;
    }
    
    // ìµœì†Œ ê°„ê²© ì²´í¬
    if (_lastSyncAttemptTime != null) {
      final timeSinceLastSync = DateTime.now().difference(_lastSyncAttemptTime!);
      if (timeSinceLastSync < SyncConstants.minSyncInterval) {
        final remainingTime = SyncConstants.minSyncInterval - timeSinceLastSync;
        _debounceSyncTimer?.cancel();
        _debounceSyncTimer = Timer(remainingTime, () {
          if (canSync && !_isSyncing) {
            startSync(retryOnFailure: true);
          }
        });
        return;
      }
    }
    
    // Debounce ì ìš©
    _debounceSyncTimer?.cancel();
    _debounceSyncTimer = Timer(SyncConstants.realtimeSyncDebounce, () {
      if (canSync && !_isSyncing) {
        startSync(retryOnFailure: true);
      }
    });
  }
  
  /// ë¡œì»¬ ë°ì´í„° ë³€ê²½ ì‹œ ë™ê¸°í™” íŠ¸ë¦¬ê±° (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
  /// triggerSyncIfAvailableë¥¼ í†µí•´ í˜¸ì¶œë¨
  void triggerSync() {
    triggerImmediateSync();
  }

  @override
  void dispose() {
    // ì£¼ê¸°ì  ìë™ ë™ê¸°í™”ëŠ” ë¹„í™œì„±í™”ë˜ì–´ íƒ€ì´ë¨¸ê°€ ì—†ìŒ (ì´ë²¤íŠ¸ ê¸°ë°˜ ë™ê¸°í™”ë§Œ ì‚¬ìš©)
    _autoSyncTimer?.cancel(); // í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    _autoSyncTimer = null;
    _stopPeriodicConnectionCheck();
    _debounceSyncTimer?.cancel();
    _debounceSyncTimer = null;
    // ë„¤íŠ¸ì›Œí¬ ë¦¬ìŠ¤ë„ˆ ì œê±° (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
    if (_networkStatusListener != null) {
      OracleNetworkMonitor().removeListener(_networkStatusListener!);
      _networkStatusListener = null;
    }
    super.dispose();
  }

  Future<void> _loadConfig() async {
    final configData = await (_db.select(_db.syncConfigs)).getSingleOrNull();
    if (configData != null) {
      // ê¸°ì¡´ ì„¤ì •ì´ ìˆìœ¼ë©´ lastSeqë§Œ ì‚¬ìš© (URLì€ AppConfigì—ì„œ ê´€ë¦¬)
      _config = model.SyncConfig(
        url: AppConfig.oracleDbApiUrl, // í•­ìƒ AppConfigì—ì„œ ê°€ì ¸ì˜´
        username: '', // ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        password: '', // ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        dbName: 'gtdoro', // ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ê²Œì´íŠ¸ì›¨ì´ì—ì„œ ì´ë¯¸ ë§¤í•‘ë¨)
        isEnabled: true, // í•­ìƒ í™œì„±í™”
        lastSeq: configData.lastSeq,
      );
      if (_config.lastSeq != null) {
        _lastSyncDisplayTime = DateTime.now();
        _lastSyncTimestamp = DateTime.now();
      }
    } else {
      // ìƒˆë¡œìš´ ì„¤ì • ìƒì„± ì‹œ lastSeqë§Œ ì´ˆê¸°í™”
      _config = model.SyncConfig(
        url: AppConfig.oracleDbApiUrl, // í•­ìƒ AppConfigì—ì„œ ê°€ì ¸ì˜´
        username: '', // ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        password: '', // ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        dbName: 'gtdoro', // ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        isEnabled: true, // í•­ìƒ í™œì„±í™”
        lastSeq: null,
      );
      
      // DBì— ì €ì¥ (lastSeqë§Œ ì €ì¥)
      final companion = SyncConfigsCompanion(
        url: Value(AppConfig.oracleDbApiUrl), // ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì €ì¥
        username: const Value(''),
        password: const Value(''),
        dbName: const Value('gtdoro'),
        isEnabled: const Value(true),
        lastSeq: const Value.absent(),
        dbType: const Value('oracle'),
      );
      await _db.into(_db.syncConfigs).insert(companion);
    }
    notifyListeners();
  }

  Future<void> updateConfig(model.SyncConfig newConfig, {bool autoSync = true}) async {
    final lastSeqChanged = _config.lastSeq != newConfig.lastSeq;
    
    if (lastSeqChanged) {
      // lastSeqë§Œ ì—…ë°ì´íŠ¸ (URLì€ AppConfigì—ì„œ ê´€ë¦¬)
      _config = model.SyncConfig(
        url: AppConfig.oracleDbApiUrl, // í•­ìƒ AppConfigì—ì„œ ê°€ì ¸ì˜´
        username: '',
        password: '',
        dbName: 'gtdoro',
        isEnabled: true,
        lastSeq: newConfig.lastSeq,
      );
      _errorMessage = null;
      try {
        final companion = SyncConfigsCompanion(
          url: Value(AppConfig.oracleDbApiUrl), // ì°¸ê³ ìš©
          username: const Value(''),
          password: const Value(''),
          dbName: const Value('gtdoro'),
          isEnabled: const Value(true),
          lastSeq: Value(_config.lastSeq),
          dbType: const Value('oracle'),
        );
        await (_db.update(_db.syncConfigs)).write(companion);
        notifyListeners();
        
        // ì„¤ì • ë³€ê²½ ì‹œ ì¦‰ì‹œ ë™ê¸°í™” (ì‹¤ì‹œê°„ ë™ê¸°í™”)
        if (autoSync && canSync && !_isSyncing) {
          dev.log('SyncProvider: Config changed, triggering immediate sync');
          Future.delayed(const Duration(milliseconds: 300), () {
            _lastSyncAttemptTime = DateTime.now();
            startSync(retryOnFailure: true);
          });
        }
      } catch (e, stackTrace) {
        dev.log('SyncProvider: Update config error', error: e, stackTrace: stackTrace);
        _errorMessage = AppStrings.errorConfigSaveFailed;
        notifyListeners();
      }
    }
  }

  Future<void> startSync({bool retryOnFailure = true, int retryCount = 0}) async {
    if (_isSyncing) {
      debugPrint('SyncProvider: â¸ï¸ Sync already in progress, skipping');
      dev.log('SyncProvider: Sync already in progress, skipping');
      return;
    }
    
    if (!canSync) {
      debugPrint('SyncProvider: âŒ Cannot sync (canSync: false)');
      dev.log('SyncProvider: Cannot sync (canSync: false)');
      return;
    }
    
    // ìµœì†Œ ê°„ê²© ì²´í¬ (ë„ˆë¬´ ë¹ ë¥¸ ì—°ì† ë™ê¸°í™” ë°©ì§€ - ì‹¤ì‹œê°„ ë™ê¸°í™” ìµœì í™”)
    // ë‹¨, ì¬ì‹œë„(retryCount > 0)ì¸ ê²½ìš°ëŠ” ìµœì†Œ ê°„ê²© ì²´í¬ë¥¼ ê±´ë„ˆëœ€
    if (_lastSyncAttemptTime != null && retryCount == 0) {
      final timeSinceLastSync = DateTime.now().difference(_lastSyncAttemptTime!);
      if (timeSinceLastSync < SyncConstants.minSyncInterval) {
        final remainingSeconds = (SyncConstants.minSyncInterval - timeSinceLastSync).inSeconds;
        debugPrint('SyncProvider: â±ï¸ Sync request too soon (${timeSinceLastSync.inSeconds}s < ${SyncConstants.minSyncInterval.inSeconds}s), scheduling in ${remainingSeconds}s...');
        dev.log('SyncProvider: Sync request too soon (${timeSinceLastSync.inSeconds}s < ${SyncConstants.minSyncInterval.inSeconds}s), scheduling for later...');
        // ìµœì†Œ ê°„ê²©ì´ ì§€ë‚˜ë©´ ë™ê¸°í™”í•˜ë„ë¡ íƒ€ì´ë¨¸ ì„¤ì •
        _debounceSyncTimer?.cancel();
        final remainingTime = SyncConstants.minSyncInterval - timeSinceLastSync;
        _debounceSyncTimer = Timer(remainingTime, () {
          if (canSync && !_isSyncing) {
            debugPrint('SyncProvider: â° Scheduled sync triggered after min interval - proceeding with sync');
            dev.log('SyncProvider: Scheduled sync triggered after min interval');
            // ì—¬ê¸°ì„œëŠ” _lastSyncAttemptTimeì„ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ - ì‹¤ì œ ë™ê¸°í™” ì‹œì‘ ì‹œ ì—…ë°ì´íŠ¸ë¨
            startSync(retryOnFailure: retryOnFailure, retryCount: 0);
          }
        });
        return;
      }
    }
    
    // ì‹¤ì œ ë™ê¸°í™” ì‹œì‘ - _lastSyncAttemptTime ì—…ë°ì´íŠ¸
    _lastSyncAttemptTime = DateTime.now();
    
    // ë„¤íŠ¸ì›Œí¬ ìƒíƒœ í™•ì¸ (ì˜¤í”„ë¼ì¸ ì‹œ ë™ê¸°í™” íì— ì¶”ê°€)
    final networkMonitor = OracleNetworkMonitor();
    if (networkMonitor.isStatusStale) {
      debugPrint('SyncProvider: Checking network status...');
      await networkMonitor.checkNetworkStatus();
    }
    
    if (networkMonitor.isOffline) {
      debugPrint('SyncProvider: âŒ Network is offline, sync will be queued for when online');
      dev.log('SyncProvider: Network is offline, sync will be queued for when online');
      _errorMessage = 'ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤. ì—°ê²° í›„ ì¦‰ì‹œ ë™ê¸°í™”ë©ë‹ˆë‹¤.';
      notifyListeners();
      // ë„¤íŠ¸ì›Œí¬ ë³µêµ¬ ì‹œ ì¦‰ì‹œ ë™ê¸°í™” (ì‹¤ì‹œê°„ ë™ê¸°í™”) - ë¦¬ìŠ¤ë„ˆ ì¤‘ë³µ ë“±ë¡ ë°©ì§€
      if (_networkStatusListener != null) {
        networkMonitor.removeListener(_networkStatusListener!);
      }
      _networkStatusListener = (isOnline) {
        if (isOnline && canSync && !_isSyncing) {
          debugPrint('SyncProvider: ğŸŒ Network recovered, triggering immediate sync');
          dev.log('SyncProvider: Network recovered, triggering immediate sync');
          // ë„¤íŠ¸ì›Œí¬ ë³µêµ¬ ì‹œ ì¦‰ì‹œ ë™ê¸°í™” (debounce ì—†ìŒ)
          Future.delayed(const Duration(milliseconds: 300), () => startSync(retryOnFailure: true));
        }
      };
      networkMonitor.addListener(_networkStatusListener!);
      return;
    }
    
    _isSyncing = true;
    _errorMessage = null;
    _currentProgress = null;
    final syncStartTime = DateTime.now();
    int itemsUploaded = 0;
    int itemsDownloaded = 0;
    
    debugPrint('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    debugPrint('SyncProvider: ğŸš€ Starting sync (attempt ${retryCount + 1})...');
    debugPrint('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    
    notifyListeners();

    try {
      // ì „ì²´ ë™ê¸°í™” ì‘ì—… íƒ€ì„ì•„ì›ƒ ì ìš© (ì•ˆì •ì„± ê°•í™”)
      final syncResult = await Future.any([
        _performSync(syncStartTime),
        Future.delayed(SyncConstants.syncOperationTimeout, () {
          throw TimeoutException(
            'Sync operation timeout after ${SyncConstants.syncOperationTimeout.inMinutes} minutes',
            SyncConstants.syncOperationTimeout,
          );
        }),
      ]);
      
      itemsUploaded = syncResult['uploaded'] ?? 0;
      itemsDownloaded = syncResult['downloaded'] ?? 0;
      
      // ì„±ê³µ ì‹œ ì¬ì‹œë„ ì¹´ìš´í„° ë¦¬ì…‹
      retryCount = 0;
    } catch (e, stackTrace) {
      if (e is TimeoutException) {
        dev.log('SyncProvider: Sync timeout', error: e, stackTrace: stackTrace);
        _errorMessage = 'ë™ê¸°í™” ì‘ì—… ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
      } else {
        dev.log('SyncProvider Error: $e', error: e, stackTrace: stackTrace);
        _errorMessage = _formatErrorMessage(e);
      }
      
      // ìë™ ì¬ì‹œë„ ë¡œì§ (ì§€ìˆ˜ ë°±ì˜¤í”„) - ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ë§Œ
      if (retryOnFailure && 
          retryCount < SyncConstants.maxRetries && 
          OracleErrorHandler.isRetryableError(e)) {
        final delaySeconds = (SyncConstants.baseRetryDelay.inSeconds * 
                              (SyncConstants.backoffMultiplier * (retryCount + 1))).round();
        final actualDelay = delaySeconds > SyncConstants.maxRetryDelay.inSeconds
            ? SyncConstants.maxRetryDelay.inSeconds
            : delaySeconds;
        dev.log('SyncProvider: Retrying sync in ${actualDelay}s (attempt ${retryCount + 1}/${SyncConstants.maxRetries})');
        
        await Future.delayed(Duration(seconds: actualDelay));
        
        // ì¬ì‹œë„ (í˜„ì¬ ìƒíƒœ ìœ ì§€)
        _isSyncing = false;
        notifyListeners();
        
        return startSync(retryOnFailure: true, retryCount: retryCount + 1);
      }
      
      // ì‹¤íŒ¨ í†µê³„ ì—…ë°ì´íŠ¸
      _updateStatistics(
        success: false,
        itemsUploaded: itemsUploaded,
        itemsDownloaded: itemsDownloaded,
        error: _errorMessage,
      );
    } finally {
      _isSyncing = false;
      _currentProgress = null;
      notifyListeners();
    }
  }
  
  /// ì‹¤ì œ ë™ê¸°í™” ì‘ì—… ìˆ˜í–‰
  Future<Map<String, int>> _performSync(DateTime syncStartTime) async {
    // 1. ì„œë²„ ì—°ê²° í™•ì¸
    await _checkServerConnection();
    
    // 2. ì„œë²„ ë©”íƒ€ë°ì´í„° ë° ì›ê²© ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ
    final serverData = await _fetchServerMetadataAndDocs();
    final serverMetadata = serverData['metadata'] as Map<String, String>;
    final remoteDocs = serverData['docs'] as List<Map<String, dynamic>>;
    final downloadResult = serverData['result'] as Map<String, dynamic>;
    
    // 3. ë¡œì»¬ ë°ì´í„° ìˆ˜ì§‘ ë° ë¹„êµí•˜ì—¬ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ ëª©ë¡ ê²°ì •
    final comparisonResult = await _compareAndFilterDocuments(serverMetadata, remoteDocs);
    final uploadList = comparisonResult['upload'] as List<Map<String, dynamic>>;
    final downloadList = comparisonResult['download'] as List<Map<String, dynamic>>;
    final conflictIds = comparisonResult['conflicts'] as Set<String>;
    
    if (conflictIds.isNotEmpty) {
      dev.log('SyncProvider: Conflicts detected - ${conflictIds.length} items need conflict resolution');
    }
    
    // 4. ì—…ë¡œë“œ ì‹¤í–‰
    final itemsUploaded = await _uploadDocuments(uploadList);
    
    // 5. ë‹¤ìš´ë¡œë“œ ë° ë³‘í•© ì‹¤í–‰
    final mergeResult = await _downloadAndMergeDocuments(downloadList, uploadList);
    final itemsDownloaded = downloadList.length;
    final successCount = mergeResult['success'] ?? 0;
    final conflictCount = mergeResult['conflicts'] ?? 0;
    final failedCount = mergeResult['failed'] ?? 0;
    
    // 6. í›„ì²˜ë¦¬ (ì‚­ì œëœ ë°ì´í„° ì •ë¦¬, ì„¤ì • ì—…ë°ì´íŠ¸)
    await _postSyncCleanup(downloadResult['last_seq'] as String?);
    
    // 7. í†µê³„ ì—…ë°ì´íŠ¸ ë° ìµœì¢… ë¡œê¹…
    _finalizeSync(syncStartTime, itemsUploaded, itemsDownloaded, successCount, conflictCount, failedCount);
    
    return {
      'uploaded': itemsUploaded,
      'downloaded': itemsDownloaded,
    };
  }
  
  /// SyncConfig í—¬í¼ - ì¤‘ë³µ ì½”ë“œ ì œê±°
  model.SyncConfig _createTempConfig({String? lastSeq}) {
    return model.SyncConfig(
      url: AppConfig.oracleDbApiUrl,
      lastSeq: lastSeq ?? _config.lastSeq,
    );
  }
  
  /// ì„œë²„ ì—°ê²° í™•ì¸
  Future<void> _checkServerConnection() async {
    _updateProgress(0, 0, 'ì—°ê²° í™•ì¸ ì¤‘...', isUpload: false);
    debugPrint('SyncProvider: Checking server connection...');
    
    final tempConfig = _createTempConfig();
    final isAlive = await _getSyncService().checkConnection(tempConfig);
    
    if (!isAlive) {
      debugPrint('SyncProvider: âŒ Server connection failed');
      throw Exception(AppStrings.errorServerConnectionFailed);
    }
    
    debugPrint('SyncProvider: âœ… Server connection successful');
  }
  
  /// ì„œë²„ ë©”íƒ€ë°ì´í„° ë° ì›ê²© ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ
  /// ìµœì í™”ëœ ë™ê¸°í™” í”Œë¡œìš°: max-rev ì²´í¬ â†’ ë™ê¸°í™” í•„ìš” ì—¬ë¶€ íŒë‹¨ â†’ metadata/delta í˜¸ì¶œ
  Future<Map<String, dynamic>> _fetchServerMetadataAndDocs() async {
    _updateProgress(0, 0, 'ì„œë²„ ìƒíƒœ í™•ì¸ ì¤‘...', isUpload: false);
    debugPrint('SyncProvider: Checking server status (max-rev)...');
    
    final syncService = _getSyncService();
    final tempConfig = _createTempConfig();
    
    Map<String, String> serverMetadata = {};
    List<Map<String, dynamic>> remoteDocs = [];
    Map<String, dynamic> downloadResult = {'docs': <Map<String, dynamic>>[], 'last_seq': null};
    
    try {
      // 1. High Water Mark ì²´í¬: max-revë¥¼ ë¨¼ì € í™•ì¸í•˜ì—¬ ë™ê¸°í™” í•„ìš” ì—¬ë¶€ ë¹ ë¥´ê²Œ íŒë‹¨
      try {
        debugPrint('SyncProvider: Checking server max-rev (High Water Mark)...');
        final serverMaxRev = await (syncService as OracleSyncService).getMaxRevBySql();
        
        if (serverMaxRev != null) {
          // ë¡œì»¬ max-rev ì¡°íšŒ
          final localMaxRev = await _getLocalMaxRev();
          
          debugPrint('SyncProvider: Server max-rev: $serverMaxRev, Local max-rev: $localMaxRev');
          
          // ë¡œì»¬ê³¼ ì„œë²„ì˜ max-revê°€ ê°™ìœ¼ë©´ ë™ê¸°í™” ë¶ˆí•„ìš” (í€µ ì²´í¬)
          if (localMaxRev != null && localMaxRev == serverMaxRev) {
            debugPrint('SyncProvider: âœ… Max-rev match! No sync needed (local: $localMaxRev, server: $serverMaxRev)');
            // ë©”íƒ€ë°ì´í„°ëŠ” ë¹ˆ ë§µ, ë¬¸ì„œë„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return {
              'metadata': <String, String>{},
              'docs': <Map<String, dynamic>>[],
              'result': {'docs': <Map<String, dynamic>>[], 'last_seq': _config.lastSeq},
            };
          } else {
            debugPrint('SyncProvider: Max-rev mismatch! Sync needed (local: $localMaxRev, server: $serverMaxRev)');
          }
        }
      } catch (e) {
        // max-rev ì²´í¬ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (í´ë°±)
        debugPrint('SyncProvider: âš ï¸ Max-rev check failed, continuing with normal sync: $e');
        dev.log('SyncProvider: Max-rev check failed', error: e);
      }
      // ì„œë²„ API í‘œì¤€ 1.0: /metadata ì—”ë“œí¬ì¸íŠ¸ë¡œ ë©”íƒ€ë°ì´í„°ë§Œ ë¨¼ì € ê°€ì ¸ì˜¤ê¸°
      try {
        debugPrint('SyncProvider: Downloading metadata from server...');
        serverMetadata = await syncService.downloadMetadataOnly(tempConfig);
        debugPrint('SyncProvider: âœ… Downloaded metadata for ${serverMetadata.length} documents');
        
        // ë©”íƒ€ë°ì´í„°ë¡œ ë¹„êµí•˜ì—¬ í•„ìš”í•œ ë¬¸ì„œ ID ëª©ë¡ ê²°ì •
        final allLocalData = await _collectLocalDataForComparison();
        final localDataMap = _buildLocalDataMap(allLocalData);
        final downloadIds = _filterDownloadIdsByMetadata(serverMetadata, localDataMap);
        
        debugPrint('SyncProvider: Identified ${downloadIds.length} documents that need download (based on metadata comparison) out of ${serverMetadata.length} total');
        
        // í•„ìš”í•œ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ìŠ¤í‚µ (ìµœì í™”!)
        if (downloadIds.isEmpty) {
          debugPrint('SyncProvider: âœ… No documents need download, skipping document download (saving bandwidth)');
          remoteDocs = [];
          downloadResult = {'docs': remoteDocs, 'last_seq': null};
        } else {
          // í•„ìš”í•œ ë¬¸ì„œë§Œ ë‹¤ìš´ë¡œë“œ: ë¸íƒ€ ë™ê¸°í™” ìš°ì„  ì‚¬ìš©
          final localMaxRev = await _getLocalMaxRev();
          if (localMaxRev != null) {
            // ë¸íƒ€ ë™ê¸°í™” ì‚¬ìš© (ì„œë²„ API í‘œì¤€ 1.0: /delta ì—”ë“œí¬ì¸íŠ¸)
            debugPrint('SyncProvider: Using delta sync for ${downloadIds.length} needed documents (local max-rev: $localMaxRev)...');
            downloadResult = await syncService.downloadChangedDocs(tempConfig, localMaxRev.toString());
            remoteDocs = (downloadResult['docs'] as List<dynamic>?)?.cast<Map<String, dynamic>>() ?? <Map<String, dynamic>>[];
            
            // í•„ìš”í•œ ë¬¸ì„œë§Œ í•„í„°ë§ (ë¸íƒ€ ë™ê¸°í™”ë¡œ ë°›ì€ ë¬¸ì„œ ì¤‘ì—ì„œ)
            remoteDocs = remoteDocs.where((doc) {
              final id = doc['_id'] as String? ?? doc['id'] as String?;
              return id != null && downloadIds.contains(id);
            }).toList();
            
            debugPrint('SyncProvider: Downloaded ${remoteDocs.length} documents via delta sync (filtered from ${downloadIds.length} needed)');
          } else {
            // ì²« ì‹¤í–‰: ì „ì²´ ë‹¤ìš´ë¡œë“œ (ì„œë²„ API í‘œì¤€ 1.0: /delta ì—”ë“œí¬ì¸íŠ¸, since_rev ì—†ì´ í˜¸ì¶œ)
            debugPrint('SyncProvider: First sync - using full download for ${downloadIds.length} needed documents...');
            remoteDocs = await syncService.downloadAllDocs(tempConfig);
            // í•„ìš”í•œ ë¬¸ì„œë§Œ í•„í„°ë§
            remoteDocs = remoteDocs.where((doc) {
              final id = doc['_id'] as String? ?? doc['id'] as String?;
              return id != null && downloadIds.contains(id);
            }).toList();
            downloadResult = {'docs': remoteDocs, 'last_seq': null};
            debugPrint('SyncProvider: Downloaded ${remoteDocs.length} documents for merge (filtered from ${downloadIds.length} needed)');
          }
        }
      } catch (e) {
        // ë©”íƒ€ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¸íƒ€/ì „ì²´ ë‹¤ìš´ë¡œë“œ ì‚¬ìš©
        debugPrint('SyncProvider: âš ï¸ Metadata-only download failed, using delta/full download: $e');
        dev.log('SyncProvider: Metadata-only download failed, using delta/full download', error: e);
        
        // ë¡œì»¬ max-rev í™•ì¸: ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¸íƒ€ ë™ê¸°í™”, ì—†ìœ¼ë©´ ì „ì²´ ë‹¤ìš´ë¡œë“œ
        final localMaxRev = await _getLocalMaxRev();
        
        if (localMaxRev != null) {
          // ë¸íƒ€ ë™ê¸°í™” ì‚¬ìš©
          debugPrint('SyncProvider: Using delta sync (local max-rev: $localMaxRev)');
          downloadResult = await syncService.downloadChangedDocs(tempConfig, localMaxRev.toString());
          remoteDocs = (downloadResult['docs'] as List<dynamic>?)?.cast<Map<String, dynamic>>() ?? <Map<String, dynamic>>[];
          debugPrint('SyncProvider: Downloaded ${remoteDocs.length} documents via delta sync');
        } else {
          // ì „ì²´ ë‹¤ìš´ë¡œë“œ (ì²« ì‹¤í–‰)
          debugPrint('SyncProvider: First sync - using full download');
          remoteDocs = await syncService.downloadAllDocs(tempConfig);
          downloadResult = {'docs': remoteDocs, 'last_seq': null};
          debugPrint('SyncProvider: Downloaded ${remoteDocs.length} total documents');
        }
        
        // ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ê¸°ì¡´ ë°©ì‹)
        serverMetadata = OracleMetadataExtractor.extractMetadataFromDocs(remoteDocs);
        debugPrint('SyncProvider: Extracted ${serverMetadata.length} server metadata entries (for _rev comparison)');
      }
    } catch (e, stackTrace) {
      debugPrint('SyncProvider: âŒ Error fetching server metadata: $e');
      dev.log('SyncProvider: Error fetching server metadata', error: e, stackTrace: stackTrace);
      // ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨í•´ë„ ì—…ë¡œë“œëŠ” ì‹œë„ (ë¶€ë¶„ ë™ê¸°í™”)
      downloadResult = {'docs': <Map<String, dynamic>>[], 'last_seq': _config.lastSeq};
    }
    
    return {
      'metadata': serverMetadata,
      'docs': remoteDocs,
      'result': downloadResult,
    };
  }
  
  /// ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìµœëŒ€ rev ê°’ ì¡°íšŒ (High Water Mark)
  /// ëª¨ë“  í…Œì´ë¸”(Actions, Contexts, RecurringActions, ScheduledActions)ì—ì„œ ìµœëŒ€ rev ê°’ ë°˜í™˜
  Future<int?> _getLocalMaxRev() async {
    try {
      int? maxRev;
      
      // ê° í…Œì´ë¸”ì—ì„œ ìµœëŒ€ rev ê°’ ì¡°íšŒ
      final actions = await (_db.select(_db.actions)
            ..orderBy([(t) => OrderingTerm.desc(t.rev)])
            ..limit(1))
          .get();
      
      if (actions.isNotEmpty && actions.first.rev != null) {
        final rev = int.tryParse(actions.first.rev!);
        if (rev != null && (maxRev == null || rev > maxRev)) {
          maxRev = rev;
        }
      }
      
      final contexts = await (_db.select(_db.contexts)
            ..orderBy([(t) => OrderingTerm.desc(t.rev)])
            ..limit(1))
          .get();
      
      if (contexts.isNotEmpty && contexts.first.rev != null) {
        final rev = int.tryParse(contexts.first.rev!);
        if (rev != null && (maxRev == null || rev > maxRev)) {
          maxRev = rev;
        }
      }
      
      final recurringActions = await (_db.select(_db.recurringActions)
            ..orderBy([(t) => OrderingTerm.desc(t.rev)])
            ..limit(1))
          .get();
      
      if (recurringActions.isNotEmpty && recurringActions.first.rev != null) {
        final rev = int.tryParse(recurringActions.first.rev!);
        if (rev != null && (maxRev == null || rev > maxRev)) {
          maxRev = rev;
        }
      }
      
      final scheduledActions = await (_db.select(_db.scheduledActions)
            ..orderBy([(t) => OrderingTerm.desc(t.rev)])
            ..limit(1))
          .get();
      
      if (scheduledActions.isNotEmpty && scheduledActions.first.rev != null) {
        final rev = int.tryParse(scheduledActions.first.rev!);
        if (rev != null && (maxRev == null || rev > maxRev)) {
          maxRev = rev;
        }
      }
      
      return maxRev;
    } catch (e, stackTrace) {
      dev.log('SyncProvider: Error getting local max-rev', error: e, stackTrace: stackTrace);
      return null;
    }
  }
  
  /// ë¡œì»¬ ë°ì´í„°ì™€ ì„œë²„ ë©”íƒ€ë°ì´í„° ë¹„êµí•˜ì—¬ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ ëª©ë¡ ê²°ì •
  /// ìµœì í™”: ë©”íƒ€ë°ì´í„°ë§Œìœ¼ë¡œ ë¹„êµ (ì´ë¯¸ _fetchServerMetadataAndDocsì—ì„œ í•„ìš”í•œ ë¬¸ì„œë§Œ í•„í„°ë§ë¨)
  Future<Map<String, dynamic>> _compareAndFilterDocuments(
    Map<String, String> serverMetadata,
    List<Map<String, dynamic>> remoteDocs,
  ) async {
    _updateProgress(0, 0, 'ë¡œì»¬ ë³€ê²½ì‚¬í•­ í™•ì¸ ì¤‘...', isUpload: true);
    debugPrint('SyncProvider: Comparing local data with server metadata...');
    
    // ë¡œì»¬ ë°ì´í„° ìˆ˜ì§‘
    final allLocalData = await _collectLocalDataForComparison();
    debugPrint('SyncProvider: Collected ${allLocalData.length} local items');
    
    // ë©”íƒ€ë°ì´í„°ë§Œìœ¼ë¡œ ì—…ë¡œë“œ ëª©ë¡ ê²°ì •
    final uploadResult = _filterUploadItems(allLocalData, serverMetadata);
    final uploadList = uploadResult['list'] as List<Map<String, dynamic>>;
    
    // remoteDocsëŠ” ì´ë¯¸ _fetchServerMetadataAndDocsì—ì„œ í•„ìš”í•œ ë¬¸ì„œë§Œ í•„í„°ë§ë˜ì—ˆê±°ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸
    // downloadIdsê°€ ë¹„ì–´ìˆìœ¼ë©´ remoteDocsë„ ë¹„ì–´ìˆìŒ (ì „ì²´ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ìŠ¤í‚µë¨)
    final downloadList = remoteDocs;
    final downloadResult = {
      'list': downloadList,
      'skipped': serverMetadata.length - downloadList.length,
    };
    
    debugPrint('SyncProvider: Using pre-filtered documents: ${downloadList.length} documents (from ${serverMetadata.length} total metadata, skipped: ${downloadResult['skipped']})');
    
    // ì¶©ëŒ ê°ì§€
    final conflictIds = _detectConflicts(uploadList, downloadList);
    
    // ë°ì´í„° ê²€ì¦
    final validatedUploadList = _validateDocuments(uploadList);
    final validatedDownloadList = _validateDocuments(downloadList);
    
    debugPrint('SyncProvider: Comparison - Upload: ${validatedUploadList.length} (skipped: ${uploadResult['skipped']}), Download: ${validatedDownloadList.length} (skipped: ${downloadResult['skipped']})');
    if (conflictIds.isNotEmpty) {
      debugPrint('SyncProvider: âš ï¸ Detected ${conflictIds.length} conflicts');
    }
    
    return {
      'upload': validatedUploadList,
      'download': validatedDownloadList,
      'conflicts': conflictIds,
    };
  }
  
  /// ë¹„êµë¥¼ ìœ„í•œ ë¡œì»¬ ë°ì´í„° ìˆ˜ì§‘
  Future<List<Map<String, dynamic>>> _collectLocalDataForComparison() async {
    final lastSeq = _config.lastSeq;
    final lastSyncTimestamp = _lastSyncTimestamp?.millisecondsSinceEpoch ?? 0;
    
    return lastSeq == null
        ? await _collectAllLocalData()
        : await _collectModifiedLocalData(lastSyncTimestamp);
  }
  
  /// ë¡œì»¬ ë°ì´í„°ë¥¼ ID ë§µìœ¼ë¡œ ë³€í™˜ (ë¹ ë¥¸ ì¡°íšŒ)
  Map<String, Map<String, dynamic>> _buildLocalDataMap(List<Map<String, dynamic>> localData) {
    final map = <String, Map<String, dynamic>>{};
    for (final doc in localData) {
      final id = doc['_id'] as String? ?? doc['id'] as String?;
      if (id != null) {
        map[id] = doc;
      }
    }
    return map;
  }
  
  /// ì—…ë¡œë“œê°€ í•„ìš”í•œ í•­ëª© í•„í„°ë§ (_rev ê¸°ë°˜)
  Map<String, dynamic> _filterUploadItems(
    List<Map<String, dynamic>> localData,
    Map<String, String> serverMetadata,
  ) {
    final uploadList = <Map<String, dynamic>>[];
    int skippedCount = 0;
    
    for (final localDoc in localData) {
      final id = localDoc['_id'] as String? ?? localDoc['id'] as String?;
      final localRev = localDoc['_rev'] as String? ?? localDoc['rev'] as String?;
      
      if (id == null) continue;
      
      final serverRev = serverMetadata[id];
      
      // ì—…ë¡œë“œ í•„ìš” ì—¬ë¶€ íŒë‹¨:
      // 1. ë¡œì»¬ì— revê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ì—…ë¡œë“œ (ìƒˆë¡œìš´ í•­ëª©)
      // 2. ì„œë²„ì— revê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ì—…ë¡œë“œ (ì„œë²„ì— ì—†ëŠ” í•­ëª©)
      // 3. ë¡œì»¬ revê°€ ì„œë²„ revë³´ë‹¤ ë” ìµœì‹ ì´ë©´ ì—…ë¡œë“œ (ë¡œì»¬ì´ ë³€ê²½ë¨)
      // 4. ë¡œì»¬ revê°€ ì„œë²„ revë³´ë‹¤ ë‚®ê±°ë‚˜ ê°™ìœ¼ë©´ ì—…ë¡œë“œí•˜ì§€ ì•ŠìŒ (ì„œë²„ê°€ ë” ìµœì‹ ì´ê±°ë‚˜ ë™ê¸°í™”ë¨)
      bool needsUpload = false;
      
      if (localRev == null || localRev.isEmpty) {
        // ë¡œì»¬ì— revê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°ì´í„°ì¼ ìˆ˜ ìˆìŒ
        // ì„œë²„ ë©”íƒ€ë°ì´í„°ì— IDê°€ ìˆëŠ”ì§€ í™•ì¸ (ì„œë²„ì— ì¡´ì¬í•˜ëŠ”ì§€)
        if (serverMetadata.containsKey(id)) {
          // ì„œë²„ì— ì¡´ì¬í•¨: revê°€ ì—†ëŠ” ê¸°ì¡´ ë°ì´í„°ì´ë¯€ë¡œ ì„œë²„ ë²„ì „ ì‚¬ìš© (ë‹¤ìš´ë¡œë“œë¨)
          needsUpload = false;
          skippedCount++;
          debugPrint('SyncProvider: Skipping upload for $id (local has no rev but exists on server - will download)');
        } else {
          // ì„œë²„ì— ì—†ìŒ: ìƒˆë¡œìš´ í•­ëª©ì´ë¯€ë¡œ ì—…ë¡œë“œ í•„ìš”
          needsUpload = true;
          debugPrint('SyncProvider: Upload needed for $id (local has no rev and not on server - new item)');
        }
      } else if (serverRev == null || serverRev.isEmpty) {
        // ì„œë²„ ë©”íƒ€ë°ì´í„°ì— IDê°€ ìˆì§€ë§Œ revê°€ ì—†ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´
        // extractMetadataFromDocsì—ì„œ revê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´('')ë¡œ ì €ì¥ë˜ë¯€ë¡œ,
        // serverMetadata.containsKey(id)ëŠ” trueì´ì§€ë§Œ serverRevëŠ” ë¹ˆ ë¬¸ìì—´
        if (serverMetadata.containsKey(id)) {
          // ì„œë²„ì— ì¡´ì¬í•˜ì§€ë§Œ revê°€ ì—†ìŒ: ê¸°ì¡´ ë°ì´í„°
          // ë¡œì»¬ì— revê°€ ìˆìœ¼ë©´ ë¡œì»¬ì´ ë” ìµœì‹ ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì§€ë§Œ,
          // ì„œë²„ì— ì´ë¯¸ ì¡´ì¬í•˜ë¯€ë¡œ ì—…ë¡œë“œ ì‹œë„í•˜ì§€ ì•Šê³  ë‹¤ìš´ë¡œë“œë¡œ ì²˜ë¦¬ (ì„œë²„ ë²„ì „ ì‚¬ìš©)
          needsUpload = false;
          skippedCount++;
          debugPrint('SyncProvider: Skipping upload for $id (local has rev $localRev but server has no rev - existing data on server, will download)');
        } else {
          // ì„œë²„ ë©”íƒ€ë°ì´í„°ì— IDê°€ ì—†ìŒ: ì„œë²„ì— ì—†ëŠ” í•­ëª©ì´ë¯€ë¡œ ì—…ë¡œë“œ í•„ìš”
          needsUpload = true;
          debugPrint('SyncProvider: Upload needed for $id (local has rev $localRev but not on server - new item)');
        }
      } else {
        // rev ë¹„êµ: ë¡œì»¬ì´ ë” ìµœì‹ ì¸ ê²½ìš°ë§Œ ì—…ë¡œë“œ í•„ìš”
        final revComparison = RevHelper.compareRev(localRev, serverRev);
        if (revComparison > 0) {
          // ë¡œì»¬ì´ ë” ìµœì‹ : ì—…ë¡œë“œ í•„ìš”
          needsUpload = true;
          debugPrint('SyncProvider: Upload needed for $id (local rev $localRev is newer than server rev $serverRev)');
        } else if (revComparison < 0) {
          // ì„œë²„ê°€ ë” ìµœì‹ : ì—…ë¡œë“œ ë¶ˆí•„ìš”, ë‚˜ì¤‘ì— ë‹¤ìš´ë¡œë“œë¨
          needsUpload = false;
          skippedCount++;
          debugPrint('SyncProvider: Skipping upload for $id (server rev $serverRev is newer than local rev $localRev)');
        } else {
          // revê°€ ê°™ìŒ: ë™ê¸°í™”ë¨, ì—…ë¡œë“œ ë¶ˆí•„ìš”
          needsUpload = false;
          skippedCount++;
        }
      }
      
      if (needsUpload) {
        uploadList.add(localDoc);
      }
    }
    
    return {'list': uploadList, 'skipped': skippedCount};
  }
  
  /// ë©”íƒ€ë°ì´í„°ë§Œìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ í•„ìš”í•œ ë¬¸ì„œ ID ëª©ë¡ ê²°ì • (ìµœì í™”)
  /// ì „ì²´ ë¬¸ì„œ ê°ì²´ë¥¼ ë§Œë“¤ì§€ ì•Šê³  ë©”íƒ€ë°ì´í„°ë§Œ ë¹„êµí•˜ì—¬ í•„ìš”í•œ IDë§Œ ë°˜í™˜
  Set<String> _filterDownloadIdsByMetadata(
    Map<String, String> serverMetadata,
    Map<String, Map<String, dynamic>> localDataMap,
  ) {
    final downloadIds = <String>{};
    
    for (final entry in serverMetadata.entries) {
      final id = entry.key;
      final serverRev = entry.value;
      
      final localDoc = localDataMap[id];
      final localRev = localDoc?['_rev'] as String? ?? localDoc?['rev'] as String?;
      
      // ë¡œì»¬ì— ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ í•„ìš”
      if (localRev == null || localRev.isEmpty) {
        downloadIds.add(id);
        continue;
      }
      
      // rev ë¹„êµë¥¼ í†µí•´ ì–´ëŠ ìª½ì´ ë” ìµœì‹ ì¸ì§€ í™•ì¸ (ì˜¤ë²„í”Œë¡œìš° ì•ˆì „ ë¹„êµ)
      final revComparison = RevHelper.compareRev(localRev, serverRev);
      
      if (revComparison < 0) {
        // ì›ê²©ì´ ë” ìµœì‹ : ë‹¤ìš´ë¡œë“œ í•„ìš”
        downloadIds.add(id);
      } else if (revComparison > 0) {
        // ë¡œì»¬ì´ ë” ìµœì‹ : ë‹¤ìš´ë¡œë“œ ë¶ˆí•„ìš”, ìŠ¤í‚µ
        debugPrint('SyncProvider: Skipping download for $id (local rev $localRev is newer than server rev $serverRev)');
      }
      // revê°€ ê°™ìœ¼ë©´ ë™ê¸°í™”ë¨, ìŠ¤í‚µ (ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ)
    }
    
    return downloadIds;
  }

  
  /// ì¶©ëŒ ê°ì§€ (ì–‘ìª½ì—ì„œ ìˆ˜ì •ëœ í•­ëª©)
  Set<String> _detectConflicts(
    List<Map<String, dynamic>> uploadList,
    List<Map<String, dynamic>> downloadList,
  ) {
    final uploadIds = uploadList
        .map((doc) => doc['_id'] ?? doc['id'])
        .whereType<String>()
        .toSet();
    final downloadIds = downloadList
        .map((doc) => doc['_id'] ?? doc['id'])
        .whereType<String>()
        .toSet();
    
    return uploadIds.intersection(downloadIds);
  }
  
  /// ë¬¸ì„œ ì—…ë¡œë“œ ì‹¤í–‰
  Future<int> _uploadDocuments(List<Map<String, dynamic>> uploadList) async {
    if (uploadList.isEmpty) {
      debugPrint('SyncProvider: No items to upload (all already synced)');
      return 0;
    }
    
    _updateProgress(uploadList.length, 0, 'ì—…ë¡œë“œ ì¤‘...', isUpload: true);
    debugPrint('SyncProvider: Uploading ${uploadList.length} items...');
    
    int itemsUploaded = 0;
    await _uploadWithProgress(_config, uploadList, (uploaded, total) {
      _updateProgress(total, uploaded, 'ì—…ë¡œë“œ ì¤‘... ($uploaded/$total)', isUpload: true);
      itemsUploaded = uploaded;
    });
    
    debugPrint('SyncProvider: âœ… Upload completed - $itemsUploaded items');
    return itemsUploaded;
  }
  
  /// ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ë° ë³‘í•© ì‹¤í–‰
  Future<Map<String, int>> _downloadAndMergeDocuments(
    List<Map<String, dynamic>> downloadList,
    List<Map<String, dynamic>> uploadList,
  ) async {
    if (downloadList.isEmpty) {
      debugPrint('SyncProvider: No items to download (all already synced)');
      _dataMerger.clearCache();
      return {'success': 0, 'conflicts': 0, 'failed': 0};
    }
    
    debugPrint('SyncProvider: Merging ${downloadList.length} remote documents...');
    
    // ë¡œì»¬ ë¬¸ì„œ ìºì‹œ ì„¤ì • (ì¶©ëŒ ê°ì§€ ìµœì í™”)
    if (uploadList.isNotEmpty) {
      final localDocsCache = <String, Map<String, dynamic>>{};
      for (final doc in uploadList) {
        final type = doc['type'] as String? ?? 'todo';
        final id = doc['_id'] as String? ?? doc['id'] as String?;
        if (id != null) {
          localDocsCache['$type:$id'] = doc;
        }
      }
      _dataMerger.setLocalDocsCache(localDocsCache);
    }
    
    // ë°ì´í„° ë³‘í•©
    _updateProgress(downloadList.length, 0, 'ë°ì´í„° ë³‘í•© ì¤‘...', isUpload: false);
    final mergeResult = await _dataMerger.mergeRemoteData(downloadList);
    
    final successCount = mergeResult['success'] ?? 0;
    final conflictCount = mergeResult['conflicts'] ?? 0;
    final failedCount = mergeResult['failed'] ?? 0;
    
    debugPrint('SyncProvider: Merge result - Success: $successCount, Conflicts: $conflictCount, Failed: $failedCount');
    
    if (failedCount > 0) {
      dev.log('SyncProvider: Warning - $failedCount documents failed to merge');
    }
    
    _dataMerger.clearCache();
    return mergeResult;
  }
  
  /// ë™ê¸°í™” í›„ì²˜ë¦¬ (ì‚­ì œëœ ë°ì´í„° ì •ë¦¬, ì„¤ì • ì—…ë°ì´íŠ¸)
  Future<void> _postSyncCleanup(String? newLastSeq) async {
    _updateProgress(0, 0, 'ì‚­ì œëœ ë°ì´í„° ì •ë¦¬ ì¤‘...', isUpload: false);
    
    try {
      await _dataMerger.purgeDeletedLocalData();
    } catch (e, stackTrace) {
      dev.log('SyncProvider: Error purging deleted data', error: e, stackTrace: stackTrace);
    }
    
    try {
      _config = _config.copyWith(lastSeq: newLastSeq ?? _config.lastSeq);
      await updateConfig(_config, autoSync: false);
    } catch (e, stackTrace) {
      dev.log('SyncProvider: Error updating config', error: e, stackTrace: stackTrace);
    }
  }
  
  /// ë™ê¸°í™” ì™„ë£Œ ì²˜ë¦¬ (í†µê³„ ì—…ë°ì´íŠ¸, ë¡œê¹…)
  void _finalizeSync(
    DateTime syncStartTime,
    int itemsUploaded,
    int itemsDownloaded,
    int successCount,
    int conflictCount,
    int failedCount,
  ) {
    final syncDuration = DateTime.now().difference(syncStartTime);
    _lastSyncDisplayTime = DateTime.now();
    _lastSyncTimestamp = DateTime.now();
    
    _updateStatistics(
      success: true,
      itemsUploaded: itemsUploaded,
      itemsDownloaded: itemsDownloaded,
      duration: syncDuration,
    );
    
    OracleCacheManager().cleanupExpiredCache();
    _updateProgress(0, 0, 'ì™„ë£Œ', isUpload: false);
    
    // ë™ê¸°í™” ì™„ë£Œ í›„ UI Provider ê°•ì œ ìƒˆë¡œê³ ì¹¨ (ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤íŠ¸ë¦¼ì´ ë³€ê²½ì‚¬í•­ì„ ê°ì§€í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ)
    // ì•½ê°„ì˜ ì§€ì—°ì„ ë‘ì–´ ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜ì´ ì™„ì „íˆ ì»¤ë°‹ëœ í›„ì— ìƒˆë¡œê³ ì¹¨
    Future.delayed(const Duration(milliseconds: 100), () {
      _refreshProviders();
    });
    
    debugPrint('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    debugPrint('SyncProvider: âœ… Sync completed successfully!');
    debugPrint('SyncProvider: Duration: ${syncDuration.inSeconds}s');
    debugPrint('SyncProvider: Uploaded: $itemsUploaded, Downloaded: $itemsDownloaded');
    if (successCount > 0 || conflictCount > 0 || failedCount > 0) {
      debugPrint('SyncProvider: Merged - Success: $successCount, Conflicts: $conflictCount, Failed: $failedCount');
    }
    debugPrint('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    dev.log('SyncProvider: Sync completed in ${syncDuration.inSeconds}s');
  }
  
  /// UI Provider ê°•ì œ ìƒˆë¡œê³ ì¹¨ (ë™ê¸°í™” ì™„ë£Œ í›„ ë°ì´í„°ë² ì´ìŠ¤ ë³€ê²½ì‚¬í•­ì´ UIì— ë°˜ì˜ë˜ë„ë¡)
  /// ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤íŠ¸ë¦¼ì´ ë³€ê²½ì‚¬í•­ì„ ê°ì§€í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬
  /// Providerì— ì§ì ‘ ì•Œë¦¼ì„ ë³´ë‚´ê±°ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ë„ë¡ ìœ ë„
  void _refreshProviders() {
    try {
      // ActionProviderëŠ” ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤íŠ¸ë¦¼ì„ êµ¬ë…í•˜ê³  ìˆìœ¼ë¯€ë¡œ,
      // ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—…ë°ì´íŠ¸ë˜ë©´ ìë™ìœ¼ë¡œ ë°˜ì‘í•´ì•¼ í•¨
      // í•˜ì§€ë§Œ ìŠ¤íŠ¸ë¦¼ì´ ë³€ê²½ì‚¬í•­ì„ ê°ì§€í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬
      // ì•½ê°„ì˜ ì§€ì—° í›„ì— ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ë„ë¡ ìœ ë„
      
      // ë°ì´í„°ë² ì´ìŠ¤ì— ì‘ì€ ë³€ê²½ì„ íŠ¸ë¦¬ê±°í•˜ì—¬ ìŠ¤íŠ¸ë¦¼ì„ í™œì„±í™”
      // í•˜ì§€ë§Œ ì´ëŠ” ë¶ˆí•„ìš”í•œ ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì´ë¯€ë¡œ, ëŒ€ì‹  Providerì— ì§ì ‘ ì•Œë¦¼
      // ActionProviderëŠ” ìŠ¤íŠ¸ë¦¼ì„ í†µí•´ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ë¯€ë¡œ,
      // ì—¬ê¸°ì„œëŠ” ëª…ì‹œì ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨í•  í•„ìš”ê°€ ì—†ìŒ
      // ëŒ€ì‹  ë°ì´í„°ë² ì´ìŠ¤ ë³€ê²½ì‚¬í•­ì´ ì œëŒ€ë¡œ ê°ì§€ë˜ë„ë¡ ë³´ì¥
      
      // ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤íŠ¸ë¦¼ì´ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ë¯€ë¡œ
      // ì—¬ê¸°ì„œëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ì‹¤ì œ ì‘ì—…ì€ í•˜ì§€ ì•ŠìŒ
      // ë§Œì•½ ìŠ¤íŠ¸ë¦¼ì´ ì—…ë°ì´íŠ¸ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ActionProviderì˜ ìŠ¤íŠ¸ë¦¼ êµ¬ë… ë¡œì§ì„ í™•ì¸í•´ì•¼ í•¨
      
      dev.log('SyncProvider: Sync completed, database streams should automatically update providers');
    } catch (e, stackTrace) {
      dev.log('SyncProvider: Error refreshing providers', error: e, stackTrace: stackTrace);
    }
  }
  
  void _updateProgress(int total, int processed, String step, {required bool isUpload}) {
    _currentProgress = SyncProgress(
      totalItems: total,
      processedItems: processed,
      currentStep: step,
      isUpload: isUpload,
      startTime: _currentProgress?.startTime ?? DateTime.now(),
    );
    notifyListeners();
  }
  
  void _updateStatistics({
    required bool success,
    int itemsUploaded = 0,
    int itemsDownloaded = 0,
    Duration? duration,
    String? error,
  }) {
    _statistics = _statistics.copyWith(
      totalSyncs: _statistics.totalSyncs + 1,
      successfulSyncs: success ? _statistics.successfulSyncs + 1 : _statistics.successfulSyncs,
      failedSyncs: success ? _statistics.failedSyncs : _statistics.failedSyncs + 1,
      lastSuccessfulSync: success ? DateTime.now() : _statistics.lastSuccessfulSync,
      lastFailedSync: success ? _statistics.lastFailedSync : DateTime.now(),
      lastError: error,
      totalItemsUploaded: _statistics.totalItemsUploaded + itemsUploaded,
      totalItemsDownloaded: _statistics.totalItemsDownloaded + itemsDownloaded,
      averageSyncDuration: duration != null
          ? Duration(
              milliseconds: ((_statistics.averageSyncDuration?.inMilliseconds ?? 0) + duration.inMilliseconds) ~/ 2,
            )
          : _statistics.averageSyncDuration,
    );
  }
  
  Future<void> _uploadWithProgress(
    model.SyncConfig config,
    List<Map<String, dynamic>> docs,
    void Function(int processed, int total) onProgress,
  ) async {
    final batchSize = SyncConstants.maxBatchSize;
    int processed = 0;
    final tempConfig = _createTempConfig();
    
    for (int i = 0; i < docs.length; i += batchSize) {
      final batch = docs.skip(i).take(batchSize).toList();
      await _getSyncService().uploadDocs(tempConfig, batch);
      processed += batch.length;
      onProgress(processed, docs.length);
    }
  }

  Future<bool> testConnection(model.SyncConfig testConfig) async {
    _isSyncing = true;
    _errorMessage = null;
    notifyListeners();

    try {
      final isAlive = await _oracleSyncService.checkConnection(testConfig);
      if (isAlive) return true;
      throw Exception(AppStrings.errorAuthFailed);
    } catch (e, stackTrace) {
      dev.log('SyncProvider: Test connection error', error: e, stackTrace: stackTrace);
      _errorMessage = _formatErrorMessage(e);
      return false;
    } finally {
      _isSyncing = false;
      notifyListeners();
    }
  }

  /// ìƒì„¸í•œ ì—°ê²° í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
  Future<ConnectionTestResult> testConnectionDetailed() async {
    final apiUrl = AppConfig.oracleDbApiUrl;
    final hasOAuth2 = AppConfig.oracleDbClientId != null && 
                     AppConfig.oracleDbClientSecret != null &&
                     AppConfig.oracleDbClientId!.isNotEmpty && 
                     AppConfig.oracleDbClientSecret!.isNotEmpty;
    
    // 1ë‹¨ê³„: ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ í™•ì¸
    bool hasNetwork = false;
    String? networkError;
    try {
      final networkMonitor = OracleNetworkMonitor();
      hasNetwork = await networkMonitor.checkNetworkStatus();
      if (!hasNetwork) {
        networkError = 'ì¸í„°ë„· ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤';
      }
    } catch (e) {
      networkError = 'ë„¤íŠ¸ì›Œí¬ í™•ì¸ ì‹¤íŒ¨: ${e.toString()}';
    }

    if (!hasNetwork) {
      return ConnectionTestResult(
        success: false,
        message: 'ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨',
        errorType: 'NetworkError',
        details: networkError ?? 'ì¸í„°ë„·ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
        testTime: DateTime.now(),
        hasNetwork: false,
        hasOAuth2: hasOAuth2,
        apiUrl: apiUrl,
      );
    }

    // 2ë‹¨ê³„: Oracle DB ì—°ê²° í™•ì¸
    try {
      final tempConfig = model.SyncConfig(
        url: apiUrl,
        lastSeq: _config.lastSeq,
      ); // testConnectionDetailedì—ì„œëŠ” apiUrlì„ ì§ì ‘ ì‚¬ìš©í•˜ë¯€ë¡œ í—¬í¼ ë¯¸ì‚¬ìš©
      
      final isConnected = await _oracleSyncService.checkConnection(tempConfig);
      
      if (isConnected) {
        return ConnectionTestResult(
          success: true,
          message: 'Oracle DBì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤',
          statusCode: 200,
          testTime: DateTime.now(),
          hasNetwork: true,
          hasOAuth2: hasOAuth2,
          apiUrl: apiUrl,
        );
      } else {
        return ConnectionTestResult(
          success: false,
          message: 'Oracle DB ì—°ê²° ì‹¤íŒ¨',
          errorType: 'ConnectionFailed',
          details: 'ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLê³¼ ì¸ì¦ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.',
          testTime: DateTime.now(),
          hasNetwork: true,
          hasOAuth2: hasOAuth2,
          apiUrl: apiUrl,
        );
      }
    } catch (e, stackTrace) {
      dev.log('SyncProvider: Detailed connection test failed', error: e, stackTrace: stackTrace);
      
      String errorType = 'UnknownError';
      String errorDetails = e.toString();
      
      if (e.toString().contains('SocketException') || e.toString().contains('Network is unreachable')) {
        errorType = 'NetworkError';
        errorDetails = 'ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ: ì„œë²„ì— ë„ë‹¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤';
      } else if (e.toString().contains('TimeoutException') || e.toString().contains('timeout')) {
        errorType = 'TimeoutError';
        errorDetails = 'ì—°ê²° íƒ€ì„ì•„ì›ƒ: ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤';
      } else if (e.toString().contains('Certificate') || e.toString().contains('SSL')) {
        errorType = 'SSLError';
        errorDetails = 'SSL ì¸ì¦ì„œ ë¬¸ì œ: ë³´ì•ˆ ì—°ê²°ì„ ì„¤ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤';
      } else if (e.toString().contains('401') || e.toString().contains('Unauthorized')) {
        errorType = 'AuthError';
        errorDetails = 'ì¸ì¦ ì‹¤íŒ¨: OAuth2 Client IDì™€ Secretì„ í™•ì¸í•˜ì„¸ìš”';
      } else if (e.toString().contains('403') || e.toString().contains('Forbidden')) {
        errorType = 'PermissionError';
        errorDetails = 'ê¶Œí•œ ì—†ìŒ: ì¸ì¦ ì •ë³´ëŠ” ì˜¬ë°”ë¥´ì§€ë§Œ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤';
      } else if (e.toString().contains('404') || e.toString().contains('Not Found')) {
        errorType = 'NotFoundError';
        errorDetails = 'ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: URLì„ í™•ì¸í•˜ì„¸ìš”';
      }
      
      return ConnectionTestResult(
        success: false,
        message: 'ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨',
        errorType: errorType,
        details: errorDetails,
        testTime: DateTime.now(),
        hasNetwork: true,
        hasOAuth2: hasOAuth2,
        apiUrl: apiUrl,
      );
    }
  }

  void clearError() {
    _errorMessage = null;
    notifyListeners();
  }

  /// Force sync from remote: Delete all local data and sync from remote only
  /// This is a destructive operation that will delete all local data
  Future<void> forceSyncFromRemote() async {
    // Prevent concurrent sync
    if (_isSyncing) {
      dev.log('SyncProvider: Sync already in progress');
      return;
    }
    
    if (!canSync) {
      dev.log('SyncProvider: Cannot sync (canSync: false)');
      throw Exception('ë™ê¸°í™” ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }
    
    _isSyncing = true;
    _errorMessage = null;
    notifyListeners();

    try {
      dev.log('SyncProvider: Force sync from remote - deleting all local data...');
      
      final tempConfig = _createTempConfig();
      
      // Check connection first
      final isAlive = await _getSyncService().checkConnection(tempConfig);
      if (!isAlive) throw Exception(AppStrings.errorServerConnectionFailed);

      // Delete all local data (ì•ˆì •ì„± ê°•í™”: íŠ¸ëœì­ì…˜ ì—ëŸ¬ ì²˜ë¦¬)
      try {
        await _db.transaction(() async {
          // Delete all actions and their contexts
          await (_db.delete(_db.actionContexts)).go();
          await (_db.delete(_db.actions)).go();
          
          // Delete all contexts
          await (_db.delete(_db.contexts)).go();
          
          // Delete all recurring actions
          await (_db.delete(_db.recurringActions)).go();
          
          // Delete all scheduled actions
          await (_db.delete(_db.scheduledActions)).go();
        });
      } catch (e, stackTrace) {
        dev.log('SyncProvider: Error deleting local data in transaction', error: e, stackTrace: stackTrace);
        throw Exception('ë¡œì»¬ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: ${e.toString()}');
      }
      
      dev.log('SyncProvider: All local data deleted, downloading from remote...');
      
      // Download all data from remote (full sync)
      final syncService = _getSyncService();
      final downloadResult = {
        'docs': await syncService.downloadAllDocs(tempConfig),
        'last_seq': null,
      };

      final remoteDocs = (downloadResult['docs'] as List<dynamic>?)
              ?.cast<Map<String, dynamic>>() ??
          <Map<String, dynamic>>[];
      final newLastSeq = downloadResult['last_seq'] as String?;

      // ë°ì´í„° ê²€ì¦ (ì•ˆì •ì„± ê°•í™”)
      final validatedRemoteDocs = _validateDocuments(remoteDocs);

      // Merge remote data (which will be all data since local is empty)
      await _dataMerger.mergeRemoteData(validatedRemoteDocs);

      // Reset lastSeq to start fresh
      _config = _config.copyWith(lastSeq: newLastSeq);
      await updateConfig(_config, autoSync: false);

      _lastSyncDisplayTime = DateTime.now();
      _lastSyncTimestamp = DateTime.now();
      dev.log('SyncProvider: Force sync from remote completed');
    } catch (e, stackTrace) {
      dev.log('SyncProvider: Force sync error', error: e, stackTrace: stackTrace);
      _errorMessage = _formatErrorMessage(e);
      rethrow;
    } finally {
      _isSyncing = false;
      notifyListeners();
    }
  }

  /// Convert error to user-friendly message
  String _formatErrorMessage(dynamic error) {
    // Oracle íŠ¹í™” ì—ëŸ¬ ì²˜ë¦¬
    return OracleErrorHandler.formatOracleError(error);
  }

  /// Oracle ë™ê¸°í™” ì„œë¹„ìŠ¤ ë°˜í™˜
  OracleSyncService _getSyncService() {
    return _oracleSyncService;
  }

  /// ê°œë³„ í•­ëª© ì¦‰ì‹œ ì—…ë¡œë“œ (ì•¡ì…˜ ì¶”ê°€/ìˆ˜ì • ì‹œ í˜¸ì¶œ)
  /// ë³€ê²½ëœ í•­ëª©ë§Œ ì›ê²© DBì— ì¦‰ì‹œ ì—…ë¡œë“œí•˜ì—¬ íš¨ìœ¨ì„± í–¥ìƒ
  Future<void> uploadSingleItem(Map<String, dynamic> item) async {
    if (!canSync || _isSyncing) {
      dev.log('SyncProvider: uploadSingleItem skipped (canSync: $canSync, isSyncing: $_isSyncing)');
      return;
    }

    // ë„¤íŠ¸ì›Œí¬ ìƒíƒœ í™•ì¸
    if (!isNetworkOnline) {
      dev.log('SyncProvider: uploadSingleItem skipped (network offline)');
      return;
    }

    try {
      final tempConfig = _createTempConfig();
      final docList = [item];
      
      dev.log('SyncProvider: Uploading single item immediately (type: ${item['type']}, id: ${item['_id'] ?? item['id']})');
      
      // ë‹¨ì¼ ë¬¸ì„œ ì—…ë¡œë“œ
      await _getSyncService().uploadDocs(tempConfig, docList);
      
      dev.log('SyncProvider: âœ… Single item uploaded successfully (type: ${item['type']}, id: ${item['_id'] ?? item['id']})');
    } catch (e, stackTrace) {
      dev.log('SyncProvider: Error uploading single item', error: e, stackTrace: stackTrace);
      // ê°œë³„ ì—…ë¡œë“œ ì‹¤íŒ¨ëŠ” ì „ì²´ ë™ê¸°í™”ì— ì˜í–¥ì£¼ì§€ ì•ŠìŒ (ì¡°ìš©íˆ ì‹¤íŒ¨ ì²˜ë¦¬)
      // ì „ì²´ ë™ê¸°í™” ì‹œ ë‹¤ì‹œ ì‹œë„ë¨
    }
  }

  /// ëª¨ë“  ë¡œì»¬ ë°ì´í„° ìˆ˜ì§‘ ë° Oracle í˜•ì‹ìœ¼ë¡œ ë³€í™˜
  Future<List<Map<String, dynamic>>> _collectAllLocalData() async {
    final List<Map<String, dynamic>> result = [];
    
    result.addAll((await _actionRepo.getAllActions())
        .map((e) => e.toOracleJson()));
    result.addAll((await _contextRepo.getAllContexts())
        .map((e) => e.toOracleJson()));
    result.addAll((await _recurringRepo.getAllRecurringActions())
        .map((e) => e.toOracleJson()));
    result.addAll((await _scheduledRepo.getAllScheduledActions())
        .map((e) => e.toOracleJson()));
    
    return result;
  }

  /// ìˆ˜ì •ëœ ë¡œì»¬ ë°ì´í„° ìˆ˜ì§‘ ë° Oracle í˜•ì‹ìœ¼ë¡œ ë³€í™˜
  Future<List<Map<String, dynamic>>> _collectModifiedLocalData(int lastSyncTimestamp) async {
    final List<Map<String, dynamic>> result = [];
    
    result.addAll((await _actionRepo.getModifiedActions(lastSyncTimestamp))
        .map((e) => e.toOracleJson()));
    result.addAll((await _contextRepo.getModifiedContexts(lastSyncTimestamp))
        .map((e) => e.toOracleJson()));
    result.addAll((await _recurringRepo.getModifiedRecurringActions(lastSyncTimestamp))
        .map((e) => e.toOracleJson()));
    result.addAll((await _scheduledRepo.getModifiedScheduledActions(lastSyncTimestamp))
        .map((e) => e.toOracleJson()));
    
    return result;
  }
  
  
  /// ë¬¸ì„œ ê²€ì¦ (ë¦¬íŒ©í† ë§: OracleDocumentHelper ì‚¬ìš©)
  List<Map<String, dynamic>> _validateDocuments(List<Map<String, dynamic>> docs) {
    final validated = <Map<String, dynamic>>[];
    
    for (final doc in docs) {
      try {
        // í•„ìˆ˜ í•„ë“œ ê²€ì¦ (ë¦¬íŒ©í† ë§: í—¬í¼ ì‚¬ìš©)
        if (!OracleDocumentHelper.isValidDocument(doc)) {
          dev.log('SyncProvider: Invalid document skipped: ${doc['_id'] ?? 'unknown'}');
          continue;
        }
        
        // ë¬¸ì„œ í¬ê¸° ê²€ì¦ (ë©”ëª¨ë¦¬ ë³´í˜¸)
        final docSize = OracleDocumentHelper.estimateDocumentSize(doc);
        if (docSize > SyncConstants.maxDocumentSize) {
          dev.log('SyncProvider: Document too large ($docSize bytes), skipped: ${doc['_id'] ?? 'unknown'}');
          continue;
        }
        
        validated.add(doc);
      } catch (e) {
        dev.log('SyncProvider: Error validating document: $e');
        // ê²€ì¦ ì‹¤íŒ¨í•œ ë¬¸ì„œëŠ” ì œì™¸í•˜ê³  ê³„ì† ì§„í–‰
        continue;
      }
    }
    
    return validated;
  }
}
